{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe elements to lowercase\n",
    "#removed stopwords\n",
    "#lemmatization and stemming to obtain base word so as to group them together \n",
    "def preprocess(data):\n",
    "    return [''.join([ss.stem(lemma.lemmatize(j))+' ' for j in str(i).split() \n",
    "                     if (j not in stpwrds) and j.isalpha()]) for i in data.str.lower()]\n",
    "\n",
    "#calculate frequency of occurence of each word occuring in the review\n",
    "def frequent(frame):\n",
    "    return frame.str.split().explode().value_counts().rename_axis('words').reset_index(name='counts')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "amazon=pd.read_csv('C:\\\\Users\\\\Pratik\\\\Desktop\\\\1611766549_6456213_train_file.dat',sep='\\t',header=None,names=['Rating','Review'])\n",
    "test_data=pd.DataFrame({'Review': open('C:\\\\Users\\\\Pratik\\\\Desktop\\\\1611766549_7170458_test.dat',\"r\")})\n",
    "\n",
    "#drop duplicates in the training data (18506 to 18499 rows)\n",
    "amazon=amazon.drop_duplicates(keep='first',inplace=False)\n",
    "\n",
    "ss=SnowballStemmer('english')\n",
    "lemma=WordNetLemmatizer()\n",
    "\n",
    "stpwrds=stopwords.words('english')\n",
    "#remove Negative words from stopwords library to retain meaning of the review\n",
    "neg_words=['ain','aren',\"aren't\",'couldn',\"couldn't\",'didn',\"didn't\",'doesn',\"doesn't\",'don',\"don't\",'hadn',\"hadn't\",'hasn',\n",
    "           \"hasn't\",'haven',\"haven't\",'isn',\"isn't\",'mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'no','nor','not',\n",
    "           'shan',\"shan't\",'shouldn',\"shouldn't\",'wasn',\"wasn't\",'weren',\"weren't\",'won',\"won't\",'wouldn',\"wouldn't\"]\n",
    "stpwrds=set(stpwrds)-set(neg_words)\n",
    "\n",
    "amazon['Rev']=preprocess(amazon['Review'])\n",
    "test_data['Rev']=preprocess(test_data['Review'])\n",
    "\n",
    "#identifying frequently occurring words to be used as features for the Training and testing matrix\n",
    "words=frequent(amazon['Rev'])\n",
    "test_words=frequent(test_data['Rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term frequencyâ€“inverse document frequency vectorizer for normalizing the word count\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec=TfidfVectorizer(use_idf=True,vocabulary=list(set(words[(words.counts>1)]['words']) & set(test_words[(test_words.counts>1)]['words'])))\n",
    "X_train=pd.DataFrame(tvec.fit_transform(amazon['Rev']).toarray(),columns=tvec.get_feature_names())\n",
    "y_train=amazon['Rating']\n",
    "X_test=pd.DataFrame(tvec.fit_transform(test_data['Rev']).toarray(),columns=tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-fold testing\n",
    "'''\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "kf=KFold(n_splits=3,random_state=None)\n",
    "acc_score = []\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_tr , X_ts = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
    "    y_tr , y_ts = y_train[train_index] , y_train[test_index]\n",
    "    calc=X_tr.dot(X_ts.T)\n",
    "    y_pred=[y_tr.iloc[calc[c].nlargest(15).index.tolist()].value_counts().idxmax() for c in calc]\n",
    "    acc_score+=[accuracy_score(y_ts, y_pred)]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split validation: 80-20 split\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "X_tr,X_ts,y_tr,y_ts=train_test_split(X_train,y_train,test_size=0.2,shuffle=True)\n",
    "calc=X_tr.dot(X_ts.T)\n",
    "y_pred=[y_tr.iloc[calc[c].nlargest(15).index.tolist()].value_counts().idxmax() for c in calc]\n",
    "acc_score=accuracy_score(y_ts, y_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code for KNN without vectorization\n",
    "'''\n",
    "y_pred=[]\n",
    "count=0\n",
    "for index,i in X_test.iterrows():\n",
    "    count+=1\n",
    "    if count>50:\n",
    "        break\n",
    "    calc=pd.DataFrame((X_train*list(i)).sum(axis=1)/((((X_train**2).sum(axis=1)).multiply(sum(np.array(i)**2)))**0.5)).replace(np.nan, 0)\n",
    "    calc.columns=['val']\n",
    "    calc['output']=np.array(y_train)\n",
    "    y_pred+=[(calc.nlargest(15,['val']))['output'].value_counts().idxmax()]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine Similarity calculate (ignoring common denominator)\n",
    "#(X_train*list(i)).sum(axis=1)/((((X_train**2).sum(axis=1)).multiply(sum(np.array(i)**2)))**0.5)\n",
    "calc=X_train.dot(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN: choosing 15 nearest neighbors having max values of cosine similarity\n",
    "#obtain +1/-1 from corresponding y_train\n",
    "#majority vote using idxmax\n",
    "y_pred=[y_train.iloc[calc[c].nlargest(15).index.tolist()].value_counts().idxmax() for c in calc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output file\n",
    "pd.DataFrame(y_pred).to_csv(path_or_buf='C:\\\\Users\\\\Pratik\\\\Desktop\\\\submission.txt',header=False,index=False,index_label=None,mode='w') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
